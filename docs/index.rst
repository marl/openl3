.. OpenL3 documentation master file, created by
   sphinx-quickstart on Thu Nov  8 16:31:30 2018.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.
.. |br| raw:: html

   <br />

OpenL3
======

.. toctree::
   :maxdepth: 2

   installation
   tutorial


OpenL3 is an open-source Python library for computing deep audio and (eventually) image embeddings.

The audio and image embedding models provided here are published as part of [1], and are based on the Look, Listen and Learn approach [2]. For details about the embedding models and how they were trained, please see:

`Look, Listen and Learn More: Design Choices for Deep Audio Embeddings <http://www.justinsalamon.com/uploads/4/3/9/4/4394963/cramer_looklistenlearnmore_icassp_2019.pdf>`_ |br|
Jason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello. |br|
IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 3852-3856, Brighton, UK, May 2019. |br|

If you use this library in your work, please consider citing our paper.


API Reference
=============
.. toctree::
    :maxdepth: 1

    api


Contribute
=============
- `Issue tracker <http://github.com/marl/openl3/issues>`_
- `Source code <http://github.com/marl/openl3>`_



Acknowledging OpenL3
====================

Please cite the following papers when using OpenL3 in your work:

[1] Look, Listen, and Learn More: Design Choices for Deep Audio Embeddings |br|
Jason Cramer, Ho-Hsiang Wu, Justin Salamon and Juan Pablo Bello |br|
Under review, 2018. |br|

[2] Look, Listen and Learn |br|
Relja ArandjeloviÄ‡ and Andrew Zisserman |br|
IEEE International Conference on Computer Vision (ICCV), Venice, Italy, Oct. 2017. |br|


Changes
=======
.. toctree::
   :maxdepth: 1

   changes


Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`


